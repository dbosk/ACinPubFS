\title{%
  Privacy-Preserving Access Control
  %for Asynchronous Message Passing
  %in Decentralized Storage
  in Publicly Readable Storage Systems
  %for Asynchronous Message Passing
  %for Online Social Networks
}
\author{%
  Daniel Bosk \and
  Sonja Buchegger
}
\institute{%
  School of Computer Science and Communication\\
  KTH Royal Institute of Technology, Stockholm, Sweden\\
  \email{\{dbosk,buc\}@kth.se}%
}
\date{IFIP Summer School\\Edinburgh, 20th August 2015}

\maketitle

\mode* % required for slides to compile without non-frame text

\begin{abstract}
  In this paper, we focus on achieving privacy-preserving access control 
  mechanisms for decentralized storage, primarily intended for an asynchronous 
  message passing setting.
  We propose two modular constructions, one using a pull strategy and the other
  a push strategy for sharing data.
  These models yield different privacy properties and requirements on the 
  underlying system.
  We achieve hidden policies, hidden credentials and hidden decisions.
  We additionally achieve what could be called \enquote{hidden policy-updates}, 
  meaning that previously-authorized subjects cannot determine if they have 
  been excluded from future updates or not.

  \keywords{%
    Privacy,
    Access Control,
    Cloud Storage,
    Decentralized Storage,
    %Anonymous Broadcast Encryption,
    Hidden Policies
    %Hidden Credentials,
    %Hidden Decisions
  }
\end{abstract}

% Since this a solution template for a generic talk, very little can
% be said about how it should be structured. However, the talk length
% of between 15min and 45min and the theme suggest that you stick to
% the following rules:
% - Exactly two or three sections (other than the summary).
% - At *most* three subsections per section.
% - Talk about 30s to 2min per frame. So there should be between about
%   15 and 30 frames, all told.

% 1) what is the concrete setting that we consider (entities and their props),
% 2) what overall functionality and security properties do we want,
% 3) how are these properties realized (protocols, composition)?
%
% - Good synonyms for "looking at":
%   - investigating, exploring, evaluating, researching, additionally;
%   - if in relation to something else: contrasting, comparing.

\acresetall{}
\section{Introduction}\label{Introduction}
% XXX Rewrite the introduction

Alice and her friends want to communicate asynchronously.
To do this they want to use a publicly available file system and write their 
messages to different files, which the other party later can read.
This is a possible architecture for \iac{DOSN}.
We are interested in enforcing access-control policies in such a public file 
system which does not have any built-in access control mechanisms.
Our approach is to introduce a layer of encryption as a logical reference 
monitor.
Beyond the expected confidentiality, Alice wants some stronger privacy 
properties as well: her friends should not be able to monitor her activity, 
e.g.\ infer with whom else she communicates, the fact that she communicates 
with others.

We will present an ideal model of communication and its desired properties in 
\cref{IdealCommunication}, this is what we want to achieve.
Then we will present the building blocks that we will use, and their 
accompanying assumptions, in \cref{BuildingBlocks}.
We will also assume a simple file system with no built-in access control.
This system is discussed and defined in \cref{FileSystem}.

Then we give two constructions that implement the functionality using different 
message passing models and analyse what properties their primitives must have 
in \cref{PullAnalysis,PushAnalysis}.
The two message passing models are called the pull model and the push model.
In the pull model Alice's friends pull new messages from Alice, whereas in the 
push model Alice's pushes new messages to her friends' inboxes.
The motivation is that the pull model is optimized for Alice and the push model 
for Alice's friends.
In a decentralized file system the pull model yields few connections for Alice,
but many for her friends (if they have more friends than Alice).
Conversely the push model yields many connections for Alice, but only one for 
her friends (they check their inbox).
In some situations connections can be expensive, e.g.\ establishing many 
Tor~\cite{Tor} circuits to transfer little data and establishing one circuit to 
transfer more data.

After presenting our constructions we shortly analyse their algorithmic 
complexity in \cref{AlgComplexity}.
Finally we compare our results to related work in \cref{RelatedWork} and 
conclude by summarizing the main contributions and future work in 
\cref{Conclusions}.


%%% The main contribution %%%%%%%%%%%%%%%%%%%%%%%%
\input{IdealModel.tex}
\input{BuildingBlocks.tex}
\input{PullModel.tex}
\input{PushModel.tex}
\input{complexity.tex}


\section{Related Work}\label{RelatedWork}

% XXX Formalize hidden policies, credentials and decisions --- but how?
%  - Hidden policies: policy-hiding ciphertext, how to formalize?
%    - Given two equally-sized ciphertexts the adversary cannot tell them 
%      apart?
%    - What about the size of the recipient set?  Padding and dummy entries 
%      should work?
%    - Probably the definition in [ANOBE] can help?
%    - Timing-attacks on the push model?  Alice writes n same-sized 
%      objects to n places within a short timespan.  How to formalize?
%  - Hidden credentials: the keys are by definition hidden, how to 
%    formalize?  In identity-based access control, is the identity itself 
%    the credential or whatever authenticates the identity?  Or both?
%  - Hidden decisions: the adversary should not be able to guess the 
%    outcome, an IND-style property.  This shouldn't be any problem to 
%    turn into a security game.

\citet{TowardsPPACwHPHCHD} identified three desirable and (conjectured 
sufficient) properties for a privacy-preserving \ac{AC} mechanism:
\begin{inparablank}
\item hidden policies,
\item hidden credentials, and
\item hidden decisions.
\end{inparablank}
The work in~\cite{TowardsPPACwHPHCHD} focused on \ac{FHE} and is thus not 
directly feasible for our purposes.
However, the properties are still relevant in our setting.

Hidden policies means that the access policy remains hidden from anyone but 
the owner and the subjects learn at most if they have access or not.
So the subjects cannot learn which other subjects can access the same object.
We arguably achieve this property in our constructions.
Furthermore, we also achieve something closer to \enquote{hidden 
  policy-changes} as well (Jealous Bob), which prevents previously-authorized 
subjects from determining whether they are no longer authorized to receive 
updates.

%Let us briefly illustrate why the hidden policies property is important.
%Bob is not allowed access to an object, but he can see that Alice is.
%Then Bob can go to Alice and either ask her about it, or otherwise force her to 
%reveal it to him --- e.g.\ by stealing her keys.
%Even if Bob was allowed access to the object it is important that he does not 
%learn the policy.
%If Bob knows that Alice also has access to the object, then he can reveal the 
%object's contents to Eve and tell Eve to blame Alice for leaking the data to 
%her.
%But if Bob did not know who else has access, then he might be the only one and 
%thus less prone to leak to Eve as he is the only one to blame.

Hidden credentials means that the subject never has to reveal the access 
credentials to anyone.
In our case this is a cryptographic key, and as a consequence we allow the 
subject to anonymously read the ciphertext from the storage node.
This means that the storage node cannot track which subjects are requesting 
access to which objects.
(If users are not anonymized, then the storage node can approximate the 
credential, i.e.\ the subject's identity.)

Hidden decisions means that no-one but the subject must learn the outcome of an 
access request.
This means that no-one should learn whether or not a subject could decrypt the 
ciphertext or not.
However, if everyone only requests ciphertexts that they know they can decrypt 
(which is the most efficient strategy), then the storage operator can easily 
guess the decision.
Most solutions probably suffer from this, including the constructions of this 
paper.
This decision together with non-anonymized users would allow the storage 
operator to infer parts of the policy, hence breaking the hidden policy 
property.
For this reason, in addition to anonymization, subjects must also request 
ciphertexts they cannot decrypt.
This can be done either by dummy requests (i.e.\ requesting objects at random) 
or by \ac{PIR} techniques, such as \ac{OT}.

We mentioned earlier the relation between the Pull Model and \ac{BE}.
The purpose of \ac{BE} is to develop methods to efficiently transmit data to 
dynamically changing target audiences \(S\subseteq U\) who are allowed to read 
the data, whereas the remaining users \(U\setminus S\) are not.
Due to the modularity of our constructions any \ac{BE} scheme fulfilling the 
properties could be plugged in and used instead of the \ac{ANOBE} scheme used 
above.
At the moment though, \ac{ANOBE} is the only known scheme that fulfils all 
requirements.
Also worthy of note is that none of the works in the \ac{BE} area has treated 
the problem of hidden policy-changes.
In fact, as is pointed out by \citet{ANOBE}, most research in \ac{BE} has been 
focused on efficiency and not privacy (beyond confidentiality).

There is also related work in the \ac{DOSN} community.
There are several proposals available for \acp{DOSN}, e.g.\ 
DECENT~\cite{DECENT}, Cachet~\cite{Cachet} and Persona~\cite{Persona}.
The \ac{AC} mechanisms in these proposals focus on providing confidentiality 
for the data.
E.g.\ Persona uses \ac{KP-ABE} to implement the \ac{AC} mechanism and
unfortunately, this yields lacking privacy: as this is not policy-hiding, 
anyone can read the \ac{AC} policies and see who may access what data.
There are also general cryptographic \ac{AC} schemes that focus on achieving 
policy-hiding ciphertexts, see the section of related work 
in~\cite{TowardsPPACwHPHCHD}.
E.g.\ \citet{PEAC} adapted \ac{PE} for the \ac{AC} mechanism in \acp{DOSN}.
Works in this area that have employed policy-hiding schemes for \acp{DOSN} have
also focused on solving the problem of re-encryption of old data upon group 
changes.
We do not solve this problem, but rather contribute the insight that it would 
violate our desired privacy properties.
So besides being more efficient in some cases, less efficient in others, they 
do not solve exactly the same problem.



\section{Conclusions}\label{Conclusions}

We wanted to achieve privacy-preserving access control enforcement in a public 
file system lacking built-in access control.
We presented two alternatives: the Pull Model and the Push Model.
Both implements the model of a publisher distributing a message to a set of 
subscribers.

The Pull Model achieves strong privacy properties.
The subscribers cannot learn who the other subscribers are even if they control 
the entire network or the whole storage system.
Further, if the publisher wishes to exclude any of the subscribers from future 
publications, then all subscribers learn that there was a policy update but no 
one learns how --- not even those excluded!

The Push Model is an interesting case.
Conceptually, the only difference between the Push and Pull models is that we 
distribute the message, instead of everyone fetching it.
This seems to yield better privacy properties at first glance, but it turns out
that we had to considerably weaken the adversary's capabilities before we could
get any security.
Hence the security guarantees are much weaker: for the Push Model the adversary 
can only control a small part of the storage system, or monitor only part of 
the network.
However, unlike in the Pull Model, when the subscriber wants to make a policy 
update, none of the subscribers will even be notified that there has been 
a policy update --- let alone determine if they have been excluded.

As was pointed out in \cref{RelatedWork}, we do not treat group management 
(i.e.\ revoking the credentials for subjects) as is done in other schemes.
If the publisher excludes a subscriber, it is only from future publications ---
not from past!
In fact, we can conclude from our treatment above that such functionality would 
actually violate the privacy properties.
Even if possible, any subject could have made a copy anyway, i.e.\ it is the 
problem of removing something from the Web.
However, other group changes are easily done, the most expensive one is to give
a new subscriber access to old publications --- this requires re-encrypting or 
resending all publications.

We can thus conclude that it is important that any optimizations to the 
constructions can be proven not to break any of the properties.
An interesting future direction would be to explore Eve's limitations in the 
Push Model a bit more.
For example, if Eve is not allowed to control all the \(k\) parallel games, 
i.e.\ that honest players play the other \(k-1\) games, would she still be able
to win?
At a first glance she would, but better understanding under what conditions 
might give us a better solution than to weaken her capabilities.

Other interesting directions are stronger deniability properties on the one 
hand, and stronger accountability on the other.
An example of improved deniability could be using a \ac{MAC} scheme for 
authentication of messages, then we no longer have the non-repudiation 
property.
Any subscriber could publish to all subscribers in the Pull Model.
An example of desired accountability would be that Bob wants to verify that 
Alice received the same message, if Eve told him that she sent a copy to Alice 
as well.


\subsubsection{Acknowledgements}

This work was inspired by work with Benjamin Greschbach and work of Oleksandr 
Bodriagov and Gunnar Kreitz.
We would like to thank the Swedish Foundation for Strategic Research for grant 
SSF FFL09-0086 and the Swedish Research Council for grant VR 2009-3793, which 
funded this work.
We would also like to thank the anonymous reviewers and especially Anja Lehmann 
for valuable feedback.


\printbibliography{}


\appendix
