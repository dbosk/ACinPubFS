\title{%
  Privacy-Preserving Access Control
  %in Decentralized Storage
  in Publicly Readable Storage Systems
  %for Asynchronous Message Passing
  %for Online Social Networks
}
\author{%
  Daniel Bosk \and
  Sonja Buchegger
}
\institute{%
  School of Computer Science and Communication\\
  KTH Royal Institute of Technology, Stockholm, Sweden\\
  \email{\{dbosk,buc\}@kth.se}%
}
\date{IFIP Summer School\\Edinburgh, 20th August 2015}

\maketitle

\mode* % required for slides to compile without non-frame text

\begin{abstract}
  In this paper, we focus on achieving privacy-preserving access control 
  mechanisms for decentralized storage, primarily intended for message passing 
  setting.
  We propose two modular constructions, one using a pull strategy and the other
  a push strategy for sharing data.
  These models yield different privacy properties and requirements on the 
  underlying system.
  We achieve hidden policies, hidden credentials and hidden decisions.
  We additionally achieve what could be called \enquote{hidden policy-updates}, 
  meaning that previously-authorized subjects cannot determine if they have 
  been excluded from future updates or not.

  \keywords{%
    Privacy,
    Access Control,
    Decentralized Storage,
    Anonymous Broadcast Encryption,
    Hidden Policies,
    Hidden Credentials,
    Hidden Decisions
  }
\end{abstract}

% Since this a solution template for a generic talk, very little can
% be said about how it should be structured. However, the talk length
% of between 15min and 45min and the theme suggest that you stick to
% the following rules:
% - Exactly two or three sections (other than the summary).
% - At *most* three subsections per section.
% - Talk about 30s to 2min per frame. So there should be between about
%   15 and 30 frames, all told.

% 1) what is the concrete setting that we consider (entities and their props),
% 2) what overall functionality and security properties do we want,
% 3) how are these properties realized (protocols, composition)?
%
% - Good synonyms for "looking at":
%   - investigating, exploring, evaluating, researching, additionally;
%   - if in relation to something else: contrasting, comparing.

\acresetall{}
\section{Introduction}\label{Introduction}
% XXX Rewrite the introduction

Alice and her friends want to communicate asynchronously.
To do this they want to use a publicly available file system and write their 
messages to different files, which the other party later can read.
We are interested in enforcing access-control policies in such a public file 
system which does not have any built-in access control mechanisms.
Our approach is to introduce a layer of encryption as a logical reference 
monitor.
Beyond the expected confidentiality, Alice wants some stronger privacy 
properties as well: her friends should not be able to monitor her activity, 
e.g.\ infer with whom else she communicates, that fact that she communicates 
with others.

We will assume a simple file system with no built-in access control.
This system is discussed and defined in \cref{FileSystem}.
We will continue to define an ideal communication functionality in 
\cref{IdealCommunication} after which we will model our constructions.
Then we give two constructions that implement the functionality using different 
strategies and analyse what properties their primitives must have in 
\cref{PullAnalysis,PushAnalysis}.
The motivation behind these two strategies is that one is optimized for Alice 
and the other for Alice's friends.
One requires potentially many connections for her friends, while the other 
requires this for Alice.
In some situations connections can be expensive, compare e.g.\ establishing 
many Tor~\cite{Tor} circuits to transfer little data and establishing one 
circuit to transfer more data.
We summarize the algorithmic complexities in \cref{AlgComplexity}.
Finally we compare our results to related work in \cref{RelatedWork} and 
conclude our work in \cref{Conclusions}.


%%% The main contribution %%%%%%%%%%%%%%%%%%%%%%%%
\input{FileSystem.tex}
\input{IdealModel.tex}
\input{PullModel.tex}
\input{PushModel.tex}


\section{Algorithmic Complexity}\label{AlgComplexity}
% XXX Actually do some measurements
% XXX Write an introduction to the section on complexities

We will now summarize the algorithmic complexity for our constructions.
The performance is interesting to evaluate from two perspectives: the 
publisher's (Alice in all examples) and the subscriber's (Bob in all examples).
From the publisher's perspective, it is interesting to investigate the needed 
space for key storage, communication complexity for publication and time 
complexity for encryption of new material.
From the subscriber's perspective, the complexity of key-storage size and the 
time-complexity of aggregating the newest published messages are the most 
interesting aspects.
An overview of the results is presented in \cref{Complexities}.

\begin{table}
  \centering
  \caption{%
    The storage, communication and time complexities in the two models.
    \(S\) is the set of friends of a user (all subscribers), \(R\) is the set 
    of recipients of a message.
  }\label{Complexities}
  \begin{tabular}{lrr}
    Publisher
    & Pull
    & Push \\
    
    \toprule

    Key-storage size
    & \(2|S|\) & \(|S|\) \\

    \pause{}%
    Ciphertext size
    & \(2|R|\) & \(|R|\) \\

    Encryption
    & \(1\) & \(|R|\) \\

    \pause{}%
    Communication
    & \(1\) & \(|R|\) \\

    \bottomrule

  \end{tabular}
  \begin{tabular}{lrr}
    Subscriber
    & Pull & Push \\
    %& \head{Pull Model} & \head{Push Model} \\
    
    \toprule

    Key-storage size
    & \(2\) & \(1\) \\

    \pause{}%
    Ciphertext size
    & \(2|R|\) & \(1\) \\

    Decryption
    & \(1\) & \(1\) \\

    \pause{}%
    Communication
    & \(1\) & \(1\) \\

    \bottomrule

  \end{tabular}
\end{table}

The space complexity for the key management is the same for both the Pull and 
Push Model.
If we have \(|S|\) subscribers, then we need to exchange and store \(O(|S|)\) 
keys:
we need one public key per friend.

The space complexity for the ciphertexts are \(O(|R|)\) for both models.
However, the Pull Model is slightly more space efficient since we need less 
signatures.
In the Push Model we require one signature per ciphertext, i.e.\ \(O(|R|)\), 
whereas for the Pull Model we only need one per message.

The time complexity for encryption depends on the underlying schemes.
But we can see that in the Push Model we get a factor \(|R|\) to that of the 
encryption scheme, whereas we have a constant factor \(1\) in the Pull 
Model.
The time complexity for decryption on the other hand has a constant factor for 
both models.

Finally, the communication complexity for the different models differ slightly.
If we look at one single instance, then we get a constant number of connections
for the subscribers.
However, most subscribers will have to pull from several publishers, this is 
the argued benefit of Push Model --- there is only one inbox to read.

%\subsection{Extensions}\label{sec:Extensions}
%% XXX Write about possible extensions to improve the scheme
%% XXX Add that we can replace PKE with SKE in the Push Model
%For performance reasons, we also look into a trade-off between using a robust, 
%key-private IND-CCA2 \ac{PKE} scheme and a semantically secure symmetric 
%encryption scheme in the \ac{ANOBE} construction.
%The reason for this is that the symmetric operations are faster than the 
%asymmetric ones.
%This is an important factor for \acp{DOSN} during e.g.~news-feed aggregation 
%when a user comes online.
%In these situations we have to handle large amounts of data, which can lead to 
%performance problems.
%
%% XXX Write about MAC for group deniability
%If we replace the signatures by \acp{MAC}, then we can achieve group 
%deniability: anyone in the group could have posted the message.


\section{Related Work}\label{RelatedWork}

% XXX Formalize hidden policies, credentials and decisions --- but how?
%  - Hidden policies: policy-hiding ciphertext, how to formalize?
%    - Given two equally-sized ciphertexts the adversary cannot tell them 
%      apart?
%    - What about the size of the recipient set?  Padding and dummy entries 
%      should work?
%    - Probably the definition in [ANOBE] can help?
%    - Timing-attacks on the push model?  Alice writes n same-sized 
%      objects to n places within a short timespan.  How to formalize?
%  - Hidden credentials: the keys are by definition hidden, how to 
%    formalize?  In identity-based access control, is the identity itself 
%    the credential or whatever authenticates the identity?  Or both?
%  - Hidden decisions: the adversary should not be able to guess the 
%    outcome, an IND-style property.  This shouldn't be any problem to 
%    turn into a security game.

\citet{TowardsPPACwHPHCHD} identified three desirable and (conjectured 
sufficient) properties for a privacy-preserving \ac{AC} mechanism:
\begin{inparablank}
\item hidden policies,
\item hidden credentials, and
\item hidden decisions.
\end{inparablank}
The work in~\cite{TowardsPPACwHPHCHD} focused on \ac{FHE} and is thus not 
directly feasible for our purposes.
However, the properties are still relevant in our setting.

Hidden policies means that the access policy remains hidden from anyone but 
the owner and the subjects learn at most if they have access or not.
So the subjects cannot learn which other subjects can access the same object.
We arguably achieve this property in our constructions.
Furthermore, we also achieve something closer to \enquote{hidden 
  policy-changes} as well (Jealous Bob), which prevents previously-authorized 
subjects from determining whether they are no longer authorized to receive 
updates.

%Let us briefly illustrate why the hidden policies property is important.
%Bob is not allowed access to an object, but he can see that Alice is.
%Then Bob can go to Alice and either ask her about it, or otherwise force her to 
%reveal it to him --- e.g.\ by stealing her keys.
%Even if Bob was allowed access to the object it is important that he does not 
%learn the policy.
%If Bob knows that Alice also has access to the object, then he can reveal the 
%object's contents to Eve and tell Eve to blame Alice for leaking the data to 
%her.
%But if Bob did not know who else has access, then he might be the only one and 
%thus less prone to leak to Eve as he is the only one to blame.

Hidden credentials means that the subject never has to reveal the access 
credentials to anyone.
In our case this is a cryptographic key, and as a consequence we allow the 
subject to anonymously read the ciphertext from the storage node.
This means that the storage node cannot track which subjects are requesting 
access to which objects.
(If users are not anonymized, then the storage node can approximate the 
credential, i.e.\ the subject's identity.)

Hidden decisions means that no-one but the subject must learn the outcome of an 
access request.
This means that no-one should learn whether or not a subject could decrypt the 
ciphertext or not.
However, if everyone only requests ciphertexts that they know they can decrypt 
(which is the most efficient strategy), then the storage operator can easily 
guess the decision.
Most solutions probably suffer from this, including the constructions of this 
paper.
This decision together with non-anonymized users would allow the storage 
operator to infer parts of the policy, hence breaking the hidden policy 
property.
For this reason, in addition to anonymization, subjects must also request 
ciphertexts they cannot decrypt.
This can be done either by dummy requests (i.e.\ requesting objects at random) 
or by \ac{PIR} techniques, such as \ac{OT}.

We mentioned earlier the relation between the Pull Model and \ac{BE}.
The purpose of \ac{BE} is to develop methods to efficiently transmit data to 
dynamically changing target audiences \(S\subseteq U\) who are allowed to read 
the data, whereas the remaining users \(U\setminus S\) are not.
Due to the modularity of our constructions any \ac{BE} scheme fulfilling the 
properties could be plugged in and used instead of the \ac{ANOBE} scheme used 
above.
At the moment though, \ac{ANOBE} is the only known scheme that fulfils all 
requirements.
Also worthy of note is that none of the works in the \ac{BE} area has treated 
the problem of hidden policy-changes.
In fact, as is pointed out by \citet{ANOBE}, most research in \ac{BE} has been 
focused on efficiency and not privacy (beyond confidentiality).

There is also related work in the \ac{DOSN} community.
There are several proposals available for \acp{DOSN}, e.g.\ 
DECENT~\cite{DECENT}, Cachet~\cite{Cachet} and Persona~\cite{Persona}.
The \ac{AC} mechanisms in these proposals focus on providing confidentiality 
for the data.
E.g.\ Persona uses \ac{KP-ABE} to implement the \ac{AC} mechanism and
unfortunately, this yields lacking privacy: as this is not policy-hiding, 
anyone can read the \ac{AC} policies and see who may access what data.
There are also general cryptographic \ac{AC} schemes that focus on achieving 
policy-hiding ciphertexts, see the section of related work 
in~\cite{TowardsPPACwHPHCHD}.
E.g.\ \citet{PEAC} adapted \ac{PE} for the \ac{AC} mechanism in \acp{DOSN}.
Works in this area that have employed policy-hiding schemes for \acp{DOSN} have
also focused on solving the problem of re-encryption of old data upon group 
changes.
We do not solve this problem, but rather contribute the insight that it would 
violate our desired privacy properties.
So besides being more efficient in some cases, less efficient in others, they 
do not solve exactly the same problem.



\section{Conclusions}\label{Conclusions}

\dots

It is important that any optimizations can be proven not to break any of the 
properties.
As could be seen in this paper, merely splitting up the \ac{ANOBE} ciphertext 
in the step from the Pull Model to the Push Model broke the ANO-IND-CCA 
property --- and needed considerable fixing!

We do not have to consider the re-encryption problem when changing group 
constellations: this would violate the property that jealous Bob cannot infer 
a change in the access policy.

If we relax Eve's control of the public file system, i.e.\ that she only 
controls parts of it, then we need less strict constructions for the composed 
protocol.

% Group management
Our scheme is, as are general \ac{BE} schemes, designed to broadcast a message 
to a dynamically changing group.
This means that we can easily change the recipient group.
However, when a new user, say Bob, is added to the group, we might want to give 
Bob access to old messages.
In our scheme we have to encrypt the message key \(k_m\) for every message 
\(m\) that we want Bob to access.

Similarly as for adding a user, when we remove a user, say Eve, from a group, 
we might want to remove Eve's clearances for the objects.
First, we can argue whether we should remove these or not.
Since Eve has had access to an object, she might already keep a copy anyway.
If we remove her clearance, then she learns that we have removed her from the 
group.
However, if we want to remove Eve's clearance, then we will have to re-encrypt 
all objects she had access to.
This is easier in the Pull Model, because in the Push Model we also need to 
update the entries in all other users' inboxes.

%% XXX Review the conclusions
%% - Ensure that the solution covers the needed properties.
%% XXX Add slides for the conclusions
%
%% XXX Improve the problem statement
%% - Clearly describe the problem before any solution
%% - What functional and security properties do we want?
%% - What properties do we need?
%%   - Do we need anonymity?
%%   - Can we make a trade-off which is good enough?
%
%% XXX Review the overview of our contributions and outline of the paper
%% - We have simplicity, more performance?
%% - What are the benefits of our scheme?
%% - What is the problem that this paper solves and how?
%% - The initial concern was performance, right?  But given the right library 
%%   this goes away, iirc.
%% - Needs more thinking.
%
%We first analysed the high-level requirements to provide hidden policies, 
%hidden credentials and hidden decisions in our setting.
%From these requirements we gave a high-level description of what the storage 
%system must be like.
%We then suggested two models for publication and subscription of content in 
%that system --- the Pull and Push Model --- and analysed what privacy 
%properties can be achieved and how in the different models and the requirements 
%for the cryptographic primitives used to implement it.
%
%From these findings we created an \ac{AC} mechanism for a decentralized storage 
%system, relying on minimal trust in other entities.
%We presented an example implementation using the \ac{ANOBE} primitive.
%Using this example we showed how to achieve different privacy properties and 
%estimated the algorithmic complexity of the two models.
%Asymptotically the two approaches have the same time and space complexities, 
%but they differ by constant factors.
%
%\mode<presentation>{%
%\subsection{Conclusions}
%\begin{frame}<presentation>{Conclusions}
%  \begin{itemize}
%    \item We focus on the access control mechanisms in a decentralized storage 
%      system for \acp{DOSN}.
%
%    \item We use only cryptographic mechanisms, we don't rely on any \acp{TTP} 
%      as reference monitors.
%
%    \item We achieve Hidden-Credentials, Hidden-Policies, and Hidden-Decisions 
%      for our scheme.
%
%    \item For this we use \ac{ANOBE}~\cite{ANOBE}.
%  \end{itemize}
%\end{frame}
%}
%
%In the Pull Model we achieve the three desired properties hidden credentials, 
%hidden decisions and hidden policies, but we reveal meta-information such as 
%our activity in the system and we are required to use a padding scheme to hide 
%the cardinality of the recipient set.
%Without the padding scheme we reveal this piece of information about the 
%policy.
%
%In the Push Model, we achieve the first two properties similarly as for the 
%Pull Model..
%For the hidden policy property we must be careful in the design of the system.
%If Alice re-uses an inbox for several friends, then those friends learn that 
%part of her access policy.
%But if we ensure that we use one inbox per friend and that it is 
%computationally infeasible to search through all objects or that we use unique 
%randomness and signature-verification keys, then we can have policy hiding in 
%the Push Model too.
%
%Although both models are asymptotically equally complex, in practice, the Push 
%Model is probably slightly more costly for the publisher while cheaper for the 
%subscriber.
%But this should be investigated in details, currently they are only theoretical 
%estimates.
%Also, the estimates are done using \ac{ANOBE} in the implementation.
%Another primitive might yield other results.
%However, in the Push Model, might be able to gain some performance by replacing 
%the robust and key-private \ac{PKE} with a symmetric cipher.
%But it is important that the symmetric cipher has properties corresponding to 
%robustness and key-privacy, as these properties are crucial to the security of 
%the \ac{ANOBE} scheme.
%
%\subsection{Future Work}
%% XXX Review the future work section
%
%\mode<presentation>{%
%\begin{frame}{Future Work}
%  \begin{itemize}
%    \item Measuring an actual implementation.
%
%      \pause{}
%
%    \item A stronger Eve:
%      \begin{itemize}
%        \item controlling the majority of the storage nodes,
%        \item actively malicious.
%      \end{itemize}
%
%      \pause{}
%
%    \item Stronger deniability properties?
%
%      \pause{}
%
%    \item Accountability properties?
%
%  \end{itemize}
%\end{frame}
%}
%
%We can see several interesting tracks to explore from this work.
%First, we would like to have stronger deniability properties in the scheme.
%In the Pull Model, any deniability relies on the indistinguishability of the 
%users, that a third party cannot distinguish between users.
%However, Bob can prove to the third party what Alice has said, since she has 
%signed her messages to provide authentication.
%This could have a negative effect on free speech.
%We should be able to fix this by using a \ac{MAC} scheme for authentication of 
%messages, then we no longer have the non-repudiation property.
%Since we use a \ac{MAC}, Bob cannot prove anything to the third party, since he 
%himself holds a copy of the \ac{MAC} key.
%In the Push Model, we can easily remove the non-repudiation property in this 
%way.
%But it must be extended to a larger group by sharing the \ac{MAC} key within 
%the group in the Pull Model.
%We would like to explore further the possibilities for Alice to deny her 
%activities in the system.
%
%The second track would be the opposite direction of deniability: namely, 
%accountability.
%One reason for this is that Bob might want to verify that Alice received the 
%same message, if Eve told him that she sent a copy to Alice as well.
%
%
%\mode<presentation>{%
%\begin{frame}
%  \begin{center}
%    Questions?
%  \end{center}
%\end{frame}
%}
%

\mode<article>{%
\subsubsection{Acknowledgements}

This work was inspired by work with Benjamin Greschbach and work of Oleksandr 
Bodriagov and Gunnar Kreitz.
We would like to thank the Swedish Foundation for Strategic Research for grant 
SSF FFL09-0086 and the Swedish Research Council for grant VR 2009-3793, which 
funded this work.
We would also like to thank the anonymous reviewers for valuable feedback.
}

\begin{frame}
\printbibliography{}
\end{frame}


\appendix
\input{ANOBE.tex}
