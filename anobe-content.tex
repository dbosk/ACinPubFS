\title{%
  Privacy-Preserving Access Control in
  Decentralized Online Social Networks using
  Anonymous Broadcast Encryption
}
\author{%
  Daniel Bosk \and
  Sonja Buchegger
}
\institute{%
  School of Computer Science and Communication\\
  KTH Royal Institute of Technology, Stockholm, Sweden\\
  Email: \email{\{dbosk,buc\}@kth.se}%
}
%\date{24th March 2015}

\mode<presentation>{%
  \begin{frame}<presentation>
    \titlepage{}
  \end{frame}
  \begin{frame}<presentation>{Overview}
    \tableofcontents
  \end{frame}
}
\mode<article>{\maketitle}

\mode* % required for slides to compile without non-frame text

\begin{abstract}
  % XXX Update the abstract
  Online social networks collect and store large amounts of private data.
  Trusting third parties with too much data is a privacy risk.
  For this reason \acp{DOSN} were proposed.
  The current research on access control in \acp{DOSN} has been focused on 
  efficiently achieving confidentiality for data.
  In this paper, we focus on achieving efficient privacy-preserving access 
  control mechanisms for the \ac{DOSN} setting, i.e.~hidden policies, hidden 
  credentials and hidden decisions.
  We design an access control scheme for two models of communication, the pull 
  model and the push model.
  These models yield different privacy properties and requirements on the 
  underlying system.
  We finally evaluate the asymptotic complexity of the two approaches.

  \keywords{%
    decentralized online social networks,
    access control,
    decentralized storage,
    anonymous broadcast encryption,
    hidden policies,
    hidden credentials,
    hidden decisions
  }
\end{abstract}

% Since this a solution template for a generic talk, very little can
% be said about how it should be structured. However, the talk length
% of between 15min and 45min and the theme suggest that you stick to
% the following rules:
% - Exactly two or three sections (other than the summary).
% - At *most* three subsections per section.
% - Talk about 30s to 2min per frame. So there should be between about
%   15 and 30 frames, all told.

\acresetall{}
\section{Introduction}
% 1) what is the concrete setting that we consider (entities and their props),
% 2) what overall functionality and security properties do we want,
% 3) how are these properties realized (protocols, composition)?
%
% - Good synonyms for "looking at":
%   - investigating, exploring, evaluating, researching, additionally;
%   - if in relation to something else: contrasting, comparing.

\mode<presentation>{%
\subsection{Problem Setting}
\begin{frame}
  \begin{itemize}

    \item \acp{OSN} collect and store large amounts of private data.

    \item This data can reveal sensitive information.

    \item Even its meta-data can reveal a lot of information.

    \item Keeping this data out of our own control is thus a risk for privacy 
      violations.

  \end{itemize}
\end{frame}
}

Online social networks collect and store large amounts of private data.
Data mining is used to monetize this data through user profiling for directed 
advertisements or for selling to third parties.
We know that this data, or even its meta-data, is sensitive and can tell a lot 
about us~\cite[e.g.][]{pregnancy}.
We have later learned that government agencies, like the \ac{NSA} and 
\ac{GCHQ}, are interested in the data found in such centralized storages 
\cite{prism}.
Keeping this data out of our own control is thus a risk for privacy violations.

\begin{frame}<presentation>
  \begin{itemize}

    \item In our work we want to decentralize the \ac{OSN}
      \begin{itemize}
        \item to get away from a central provider,
        \item to keep the users in control of their data.
      \end{itemize}

    \item This way the users will control their data.

    %\item The system gets increased censorship resistance.

  \end{itemize}
\end{frame}

These risks were considered already in 2009 and \acp{DOSN} were suggested to 
provide against them~\cite[e.g.][]{Peerson}.
% XXX 'it' refers to the data or the central provider?  
\acp{DOSN} come with the benefits that users can keep control of their data, 
there is no central provider through which third parties (by force) can access 
the data, and it is more difficult to censor.
However, more research is required to ensure security and privacy in \acp{DOSN}, as 
the decentralized structure opens up for other risks---even when the data is 
encrypted~\cite{DevilInMetadata} (we will see an example in 
Sect.~\ref{sec:PullModelAC}).

% XXX Emphasize the main purpose of the work
In this work, we focus on \ac{AC} in such decentralized systems.
The main aim of \ac{AC} is to ensure confidentiality and integrity for the user 
data.
There are several approaches to implement \ac{AC}, the classical approach is to 
rely on a \ac{TTP} as a reference monitor~\cite{AccessControl}.
Centralized \acp{OSN} such as Facebook or Google+ are examples of using 
a \ac{TTP}, and the Snowden revelations~\cite{prism} have proved centralized \acp{OSN} a risk.
% XXX Is "reference monitor" the same as "access control"? If not, you might need to introduce the new term.
Another way to implement the reference monitor is through cryptography, and 
with cryptography we can remove the need for trust.
This way anyone may read the encrypted data and we can be sure that only those 
to whom we have given the proper keys can understand it, also they can verify who
the author is.
This is the approach we explore in this paper.
Previous research has already identified many pitfalls in this approach, 
e.g.~\cite{DevilInMetadata}, thus the purpose is not to find pitfalls, but to 
find efficient mechanisms to avoid them.

\citet{TowardsPPACwHPHCHD} identified three desirable and sufficient properties for a privacy-preserving \ac{AC} mechanism.
The properties are:
\begin{description}
  \item[Hidden-Credentials] The reference monitor cannot learn a subject's 
    credentials, despite using them in the access decision.
    As such, the reference monitor cannot track which subjects are requesting 
    access.
  \item[Hidden-Policies] The access policy remains hidden from the subjects, 
    i.e.\ the subjects cannot learn which other subjects can access the same 
    object.
  \item[Hidden-Decisions] The reference monitor cannot learn the outcome of an 
    access decision, but the policy is still enforced.
\end{description}

\subsection{Our Contributions}
% XXX Improve the problem statement
% - Clearly describe the problem before any solution
% - What functional and security properties do we want?
% - What properties do we need?
%   - Do we need anonymity?
%   - Can we make a trade-off which is good enough?

% XXX Review the overview of our contributions and outline of the paper
% - We have simplicity, more performance?
% - What are the benefits of our scheme?
We have created an \ac{AC} mechanism for a decentralized storage system, 
relying on minimal trust in other entities.
In Sect.~\ref{sec:Design} we present two approaches which both achieve the 
properties above:
hidden-credentials,
hidden-policies,
hidden-decisions.
One approach is within the pull model and the other in the push model.
Under the pull model subjects fetch data from an index, whereas, under the push 
model subjects receive data through an inbox.
We also analyse under which conditions we can achieve the different properties 
and state some requirements for the system.
In Sect.~\ref{sec:SystemModel} we outline the underlying assumptions and the 
context for our work.

We also estimate the performance of the two approaches in 
Sect.~\ref{sec:PerformanceEvaluation}.
Asymptotically the two approaches have the same time and space complexities.
However, in practice, the constants will probably make a difference.


\section{Related Work}\label{sec:RelatedWork}
% XXX Add a summarizing intro paragraph to Related Work
% XXX Clarify why some of the related work is presented here and some in the subsections. For example if these ones are central and other ones not.

The work of \citet{TowardsPPACwHPHCHD} is focused on a general solution for 
privacy-preserving \ac{AC}.
They build their solution on fully homomorphic encryption, and as such, the 
scheme is not yet practically feasible.
However, there is also a body of work which is practically feasible and is applied in our setting.
There are several proposals available for \acp{DOSN}, e.g.~DECENT
\cite{DECENT}, Cachet~\cite{Cachet} and Persona~\cite{Persona}.
The \ac{AC} mechanisms in these proposals focus on providing confidentiality for the data. They use \ac{ABE}~\cite{abe} to implement the \ac{AC} mechanism and
unfortunately, this yields lacking privacy: as \ac{ABE} is not policy-hiding, 
anyone can read the \ac{AC} policies and see who may access what data.

\citet{PEAC} adapted \ac{PE} for the \ac{AC} mechanism in \acp{DOSN}.
% XXX What properties did the PE scheme achieve?
%The scheme achieved the properties X.
% XXX What are the problems with the PE scheme?
% - More flexibility but less scalability?
For the \ac{PE} scheme, the storage complexity for keys is exponential and it 
requires \(O(2^g)\) keys, where \(g\) is the number of groups a user is 
a member of.
The key size is also bound to the expressibility of the policy, e.g.\ we can 
estimate from the size of my key how many other individuals and groups are 
accounted for in the policy.
As this scheme reveals such meta-information, it is not satisfactory.

\subsection{Broadcast Encryption}\label{sec:BE}

The purpose of \ac{BE}~\cite{broadcastenc} is to develop methods to 
efficiently transmit data to dynamically changing target audiences 
\(S\subseteq U\) who are allowed to read the data, whereas the remaining users 
\(U\setminus S\) are not.
This scenario fits our use-case well.
However, most research in \ac{BE} has been focused on efficiency and not privacy.
Thus schemes usually require that the set \(S\) is revealed as it is required 
for the members \(s\in S\) to know \(S\) for decryption.
\citet{PseudonymousBE} adapted a \ac{BE} scheme using pseudonyms, but 
pseudonyms yield a limited anonymity property~\cite{PseudonymousBE}.
Due to this limitation of \ac{BE} schemes, \citet{ANOBE} developed \ac{ANOBE}, 
where the goal was to allow decryption without knowing \(S\).
% XXX Why is ANOBE expensive?
The complexity of the \ac{ANOBE} scheme is linear in the size of the recipient 
set, i.e.~\(O(|S|)\), whereas constant-size ciphertexts\footnote{%
  This does not include the description of the set \(S\), which is needed for 
  decryption.
  So we should add another \(|S|\) bits per ciphertext (if we do not use any 
  type of coding scheme to reduce it further).
}, \(O(1)\), has been achieved for non-anonymous \ac{BE}.

\subsection{Anonymous Broadcast Encryption}\label{sec:ANOBE}

The main idea of \ac{ANOBE} is to distribute a key \(k\) to a subset of users, 
such that they can decrypt the broadcast message encrypted with \(k\) but no 
one else can.
The users who receive \(k\) should not be able to figure out who else received 
\(k\) and who did not.
This is a suitable mechanism for \ac{DOSN} as publishing a message to all 
friends is basically a broadcast to all or a subset of friends in the network.

The \ac{ANOBE} scheme was specifically designed to hide the recipient set.
This is an important property as all ciphertexts are world-readable.
If we do not have this property, then a non-intended recipient \(u\notin S\) 
can learn who is a valid recipient.
If \(u\notin S\) learns the recipient set \(S\), then \(u\) might target the 
users in \(S\) to learn the broadcast data.
It is also of interest that the privileged users \(s\in S\) cannot see who else 
is in \(S\).
In this case, a user \(s\in S\) might tell \(u\notin S\) about the message and 
blame another user \(s^\prime\in S\) for leaking.
But if \(s\in S\) might be the only person to learn the broadcast message, he 
might be discouraged to tell \(u\) as he might be the only one to blame.

% XXX Review details on ANOBE in related work
% - Move details to later in the paper, or
% - add more details about how it works?
For \ac{ANOBE} to accomplish this, we require an encryption scheme which is 
key-private~\cite{KeyPrivacy}.
This property ensures that, given a ciphertext, an eavesdropper cannot tell 
which public key, out of a set of public keys, was used to generate the 
ciphertext.
Another property we need for the encryption scheme is 
robustness~\cite{RobustEncryption}.
Robust encryption ensures that we cannot create a ciphertext which is valid for 
two different recipients:
if we have a set of possible recipients \(R\), we encrypt a message for one of 
them, \(r\in R\), then all \(r^\prime\neq r\) must decrypt the ciphertext to an 
invalid message under their keys.

It is worth noting that both of the above properties, key-privacy and 
robustness, are defined for \ac{PKE}, and \ac{ANOBE} is designed around 
different \ac{PKE} and \ac{IBE} schemes.
As we will see in Sect.~\ref{sec:PushModelAC}, in our setting it might not be 
necessary to use \ac{PKE}.


\section{System Model}\label{sec:SystemModel}

The system model we work in will be relevant to our design.
Thus we need to make some assumptions about the entities and their 
properties.
We also need to make assumptions about the properties of the underlying 
communication system.
Finally, there are different ways to implement the \ac{DOSN} architecture, and 
we cover two dichotomous models.

\subsection{The Entities and Their Properties}\label{sec:EntitiesProperties}

\mode<presentation>{%
\begin{frame}<presentation>
  \begin{itemize}

    \item We assume there exists a distributed storage system:
      \begin{itemize}
        \item All users can create new objects.
        \item Any user can read any object.
        \item Only the owner can modify an object.
        \item An owner can optionally allow others to append.
      \end{itemize}

    \item Since it's distributed we have a set of distributed storage nodes.

  \end{itemize}
\end{frame}
}

The main entities are users (or \emph{subjects}) who want to access 
\emph{objects} stored on different \emph{storage nodes}.
In essence, the storage nodes can be thought of as \ac{WWW} servers which serve 
only static objects, ciphertexts in our case.
More specifically, we want the following properties:
\begin{itemize}
    \item All users can create objects with unique names, i.e.\ analogous publishing static content on the \ac{WWW}.
    \item The object name is actually a \ac{URI}~\cite{rfc3986}:
one part of the name indicates the address of the object, i.e.\ which storage 
node that holds the object;
the remaining part of the name makes the object uniquely identifiable in the 
storage node.
    \item All objects are world readable and only the owner of an object can modify it.
However, we optionally have an append operation which is available to all 
users, provided that the owner has enabled it for the object in question.
\end{itemize}
% XXX Put a good reference to NebuloStore here

\mode<presentation>{%
\subsection{Trust}
\begin{frame}<presentation>
  \begin{itemize}

    \item The users have limited trust in the storage nodes.

    \item We trust the storage nodes to keep \enquote{something} online.

  \end{itemize}
\end{frame}
}

We want the users to have limited trust in the storage nodes.
Users can trust that the storage node will keep the data available 
\cite{DataAvailability,ReplicaPlacement}, but we do not want them to trust the 
nodes more than that.
We assume that users and storage nodes set up some scheme for (possibly 
anonymous) authentication when they agree on the \enquote{storage contract} for 
replica placement~\cite{ReplicaPlacement}.

\subsection{The Underlying Communication}\label{sec:CommModel}

\mode<presentation>{%
\begin{frame}<presentation>
  \begin{itemize}

    \item We also assume that we can anonymize the users and storage nodes.

    \item This can be accomplished using e.g.~Tor.

  \end{itemize}
\end{frame}
}

We assume that the underlying communication is run on top of an anonymization 
network, e.g.\ using onion routing as in Tor~\cite{Tor}.
This way we can assume that the users and storage nodes remain anonymous.
More specifically, we want the origin of two requests to be
indistinguishable to the storage node, so the storage node cannot differentiate 
between the same user making two requests or two users making one request each.

\subsection{The \acs{DOSN} Architecture}\label{sec:DOSN}

There are several ways to implement the message passing for the social 
communication in the \ac{DOSN}.
We will focus on two models of this communication: the push model and the pull 
model.

The pull model is similar to the \ac{WWW} analogy given above.
In this model, each user has an \emph{index} (e.g.\ user profile) stored in an 
object.
In the set-up phase, when Alice becomes friends with Bob, she gives him the 
object-name of her index and they agree on a key.
This key can be either Bob's public key or they generate and agree on 
a symmetric key.
(We will elaborate on the needed properties of the encryption scheme below.)
When Alice wants to publish new material, she updates her index.
Later, whenever Bob is interested in seeing new posts by Alice, he can read her 
index, i.e.\ pull new content from Alice's index.

The push model is the converse of the pull model.
The set-up phase is similar, the difference is that Bob will give Alice the 
object name of an \emph{inbox} and ask her to put all her new posts there.
When Alice wants to publish new content, she knows that Bob is interested, so 
she appends a copy to his inbox object.
(Note that this is why we want the append functionality mentioned earlier in 
Sect.~\ref{sec:EntitiesProperties}.)


\section{Adversary Model}\label{sec:Adversary}

The adversary Eve wants to learn any information about the users.
Thus Eve will control one or more of the storage nodes in the network.
As a storage node operator, Eve will monitor the interactions with different 
users.
Further, she is active, but she will only modify objects: either by appending 
them or removing parts of them.
Eve will not make any modification to the objects which is detectable by the 
user.
The reason for this is that once a user detects that the storage node is 
malicious, all users might stop using that storage node.
And Eve's goal is to learn information about the users, so that will not 
benefit her.
Hence she is not interested in denying service either.

Eve will also act as a user.
She will try to make friends with other users, to gain access to plaintexts of 
their messages and to be able to post messages to them.


\section{Design of the Access Control Mechanism}\label{sec:Design}
% XXX Review the Design section
% - Check that we recap what functional and security properties we want.

There are several ways to implement this protocol, each having its own benefits.
We will start by describing the simplest version, which is plain \ac{ANOBE} as 
in~\cite{ANOBE}.
We will start with applying \ac{ANOBE} for \ac{AC} in the pull model, and then in the push model.
%Later, we will describe some extensions.

\subsection{Access Control in the Pull Model}\label{sec:PullModelAC}

We have Alice who wants to use the pull model for sharing data with her 
friends.
In this model, Alice will encrypt the message \(m\) she wants to share under 
a key \(k_m\), using an authenticated encryption scheme.
She will publish the ciphertext in an object, then publish a link to the object 
in her index object.
The protocol is illustrated in Fig.~\ref{fig:PullModel}, the details follow.

\begin{figure}
  \centering
  \begin{sequencediagram}

    \newinst{A}{Alice}
    \newinst[1]{E}{Eve}
    \newinst[1]{B}{Bob}

    \begin{sdblock}{Set-up}{}
      \mess{A}{}{B}
      \node[anchor=east] at (mess from) {%
        $\PubKey{A}, \VerifKey{A}$
      };

      \mess{B}{}{A}
      \node[anchor=west] at (mess from) {%
        $\PubKey{B}, \VerifKey{B}$
      };

      \mess{A}{}{B}
      \node[anchor=east] at (mess from) {%
        \shortstack{$c = \Enc_{\PubKey{B}}( i_A )$,\\
          $\sigma = \Sign_{\SignKey{A}}( c )$}
      };
    \end{sdblock}

    \begin{sdblock}{Publication}{}
      \mess{A}{write}{E}
      \node[anchor=east] at (mess from) {%
        $c_m = \AuthEnc_{\Key{m}}( m )$
      };
      \node[anchor=west] at (mess to) {%
        $o_m$
      };

      \mess{A}{append}{E}
      \node[anchor=east] at (mess from) {%
        \shortstack{$( \VerifKey{m}, \{c_{\pi(j)}\}_j, 
          \sigma_{\{c_{\pi(j)}\}_j} )$}
      };
      \node[anchor=west] at (mess to) {%
        $i_A$
      };

      \mess{B}{read}{E}
      \node[anchor=west] at (mess from) {%
        $i_A$
      };

      \mess{E}{}{B}
      \node[anchor=east] at (mess from) {%
        \shortstack{$( \VerifKey{m}^\prime, \{c_{\pi(j)}^\prime\}_j, 
          \sigma_{\{c_{\pi(j)}\}_j}^\prime )$}
      };

      \mess{B}{read}{E}
      \node[anchor=west] at (mess from) {%
        $o_m^\prime$
      };

      \mess{E}{}{B}
      \node[anchor=east] at (mess from) {%
        $c_m^\prime$
      };

    \end{sdblock}

  \end{sequencediagram}
  \caption{%
    Illustration of the protocol adapted for the pull model.
    Eve operates all the storage nodes, thus she will return possibly modified 
    data, indicated by the primes (\(\prime\)).
  }\label{fig:PullModel}
\end{figure}

\subsubsection{Set-up}

We assume that Alice and Bob already have securely exchanged public keys and 
signature-verification keys,
%e.g.\ through~\cite{OTPKX},
so let \(\PubKey{A}, \PriKey{A}\) denote Alice's public and private key, 
respectively, and let \(\PubKey{B}, \PriKey{B}\) be Bob's.
Let \(\SignKey{A}, \VerifKey{A}\) denote Alice's signing key and verification 
key, respectively, and let \(\SignKey{B}, \VerifKey{B}\) be Bob's.
When Alice wants to add Bob as a friend, she sends the name of her index object 
\(i_A\) to Bob:
she computes the ciphertext \(c = \Enc_{\PubKey{B}}( i_A )\) and the signature 
\(\sigma = \Sign_{\SignKey{A}}( c )\), then she sends \((c, \sigma)\) to Bob.

\subsubsection{Publication}

When Alice wants to publish a message \(m\) to a subset \(S = \{i_1, \ldots, 
  i_l\}\subset U\) of her friends she does the following.
%uses a \ac{KEM}, in the case of \ac{ANOBE}~\cite{ANOBE} this is the 
%Kurosawa-Desmedt \ac{KEM}~\cite{KD-KEM}.
First Alice creates a secret key \(\Key{m}\) and a one-time signature-verification key-pair \(\SignKey{m}, \VerifKey{m}\).

Next, Alice computes \(c_m = \AuthEnc_{\Key{m}}( m )\), where \(\AuthEnc\) is 
an authenticated encryption scheme, and creates a new object with the name 
\(o_m\) which contains \(c_m\).
The object \(o_m\) can be on any storage node in the system.
Alice simply generates a random object name that does not already exist.

After that, she computes \(c_j = \Enc_{\Key{i_j}}( k_m, v_m, o_m )\) for 
\(1\leq j\leq l\).
She then lets the ciphertext \(c_{\Key{m}} = (\VerifKey{m}, c_{\pi(1)}, \ldots, 
  c_{\pi(l)}, \sigma_{\Key{m}})\), where \(\sigma_{\Key{m}} 
  = \Sign_{\SignKey{m}}( c_{\pi(1)}, \ldots, c_{\pi(l)} )\) and \(\pi\colon 
  \{1,\ldots,l\}\to \{1,\ldots,l\}\) is a random permutation.

Finally, Alice generates a signature \(\sigma_{c_{\Key{m}}} 
  = \Sign_{\SignKey{A}}( c_{\Key{m}} )\) using her signing key \(\SignKey{A}\) 
which must be shared with at least all her friends in \(S\).
Then she appends \((c_{\Key{m}}, \sigma_{c_{\Key{m}}})\) to her index object 
\(o_{i_A}\).

\subsection{Security in the Pull Model}\label{sec:PullModelSec}
% XXX Review the security analysis for the pull model scheme

%\begin{frame}<presentation>
%  \begin{itemize}
%
%    \item We can achieve Hidden-Credentials since we use crypto.
%
%    \item I'm allowed to access the object if I have a key which can decrypt 
%      it.
%
%    \item This will not reveal the credential to the storage node.
%
%  \end{itemize}
%\end{frame}

The hidden-credentials property is achieved in the pull model: a user's key 
serves as a credential to allow access.
As all users can read an object and every user is indistinguishable, then there 
is no need for a user to show any type of credential to the storage node and 
the storage node cannot identify any of the users.
Thus the access credentials are hidden.

%\begin{frame}<presentation>
%  \begin{itemize}
%
%    \item We similarly achieve Hidden-Decisions.
%
%    \item The storage node cannot tell if the \ac{AC} decision is positive or 
%      negative.
%
%    \item As I alone know if I can decrypt or not.
%
%  \end{itemize}
%\end{frame}

The hidden-decisions property is also achieved in the pull model: a user 
requests a ciphertext, the storage node does not learn whether the user can 
decrypt it or not.
Thus the access decisions are hidden.
However, if all users only download ciphertexts they can decrypt, then this 
will not hold:
if the storage-node operator always guesses that the decision was 
\enquote{allowed}, then he will be correct in the majority of the cases.

\begin{frame}<presentation>
  \begin{itemize}

    \item The last property is the Hidden-Policies.
      
    \item This requires that there is no \ac{ACL} indicating who can decrypt.

    \item This is a problem we need to solve, since it requires a lot of 
      computation doing trial-and-error to see if I can decrypt or not.

  \end{itemize}
\end{frame}

The last property, hidden policies, states that no user shall learn anything 
about who else is authorized or unauthorized to access a certain object.
Due to the anonymity property of the \ac{ANOBE} scheme, the ciphertexts do not 
reveal the intended recipient and, consequently, not the access policy.

There is some meta-information that can be inferred in the pull model.
First, in the pull model, we reveal the cardinality of the recipient set to 
everyone.
Since everyone can read the index, they can also read the number of 
sub-ciphertexts contained in the ciphertext \(c_{\Key{m}}\).

Second, assume that we are friends with Alice, so we can read and decrypt 
entries in her index \(i_A\).
If Alice decides to remove us as a friend, then we will notice that we can no 
longer decrypt the entries showing up in her index.
Hence we can infer that Alice has removed us from her list of friends.
We can then argue that Alice might be posting to several groups in the same 
index, and that she just stopped posting to our group, but this allows us to 
monitor Alice's communication activities.

\subsection{Access Control in the Push Model}\label{sec:PushModelAC}

Now Alice wants to use the push model for sharing data with her friends.
The push model is conceptually different from the pull model in that Alice will 
publish the link to the object in all her friends' inboxes, instead of in her 
own index.
This also allows us to use a \ac{MAC} instead of a digital signature for 
authentication.
The benefit is that we remove the non-repudiation property, but this comes at 
the cost of slightly more computations.
The protocol is illustrated in Fig.~\ref{fig:PushModel}, the details follow.

\begin{figure}
  % XXX Review the Push-Model Protocol figure
  \centering
  \begin{sequencediagram}

    \newinst{A}{Alice}
    \newinst[1]{E}{Eve}
    \newinst[1]{B}{Bob}

    \begin{sdblock}{Set-up}{}
      \mess{A}{}{B}
      \node[anchor=east] at (mess from) {%
        $\PubKey{A}, \VerifKey{A}$
      };

      \mess{B}{}{A}
      \node[anchor=west] at (mess from) {%
        $\PubKey{B}, \VerifKey{B}$
      };

      \mess{A}{}{B}
      \node[anchor=east] at (mess from) {%
        \shortstack{$c = \Enc_{\PubKey{B}}( i_A )$,\\
          $\sigma = \Sign_{\SignKey{A}}( c )$}
      };
    \end{sdblock}

    \begin{sdblock}{Publication}{}
      \mess{A}{write}{E}
      \node[anchor=east] at (mess from) {%
        $c_m = \AuthEnc_{\Key{m}}( m )$
      };
      \node[anchor=west] at (mess to) {%
        $o_m$
      };

      \mess{A}{append}{E}
      \node[anchor=east] at (mess from) {%
        $( \VerifKey{m}, c_{B}, \mu_{c_B} )$
      };
      \node[anchor=west] at (mess to) {%
        $i_B$
      };

      \mess{B}{read}{E}
      \node[anchor=west] at (mess from) {%
        $i_B$
      };

      \mess{E}{}{B}
      \node[anchor=east] at (mess from) {%
        $( \VerifKey{m}^\prime, c_{B}^\prime, \mu_{c_{B}^\prime} )$
      };

      \mess{B}{read}{E}
      \node[anchor=west] at (mess from) {%
        $o_m^\prime$
      };

      \mess{E}{}{B}
      \node[anchor=east] at (mess from) {%
        $c_m^\prime$
      };

    \end{sdblock}

  \end{sequencediagram}
  \caption{%
    Illustration of the protocol adapted for the push model.
    Eve operates all the storage nodes, thus she will return possibly modified 
    data, indicated by the primes (\(\prime\)).
    The difference from Fig.~\ref{fig:PullModel} is that Alice appends to 
    \(i_B\) instead of \(i_A\), she only includes \(c_B\) instead of 
    \(\{c_i\}_{i\in S}\), and she uses \(\mu_{c_B}\) instead of 
    \(\sigma_{\{c_i\}_{i\in S}}\).
  }\label{fig:PushModel}
\end{figure}

\subsubsection{Set-up}

The set-up phase for the push model is similar to that of the pull model.
When Alice wants to add Bob as a friend, she generates and sends a \ac{MAC} key 
\(\MACKey{B}\) to Bob:
she computes the ciphertext \(c_{\MACKey{B}} = \Enc_{\PubKey{B}}( \MACKey{B} 
  )\) and the signature \(\sigma_{\MACKey{B}} = \Sign_{\SignKey{A}}( 
  c_{\MACKey{B}} )\), then she sends \((c_{\MACKey{B}}, \sigma_{\MACKey{B}})\) 
to Bob.
Bob then replies with the name of his inbox object, \(i_B\):
he computes \(c_{i_B} = \Enc_{\PubKey{A}}( i_B )\) and \(\sigma_{i_B} 
  = \Sign_{\SignKey{B}}( c_{i_B} )\) and sends them to Alice.

\subsubsection{Publication}

Again, Alice wants to publish a message \(m\) to a subset \(S = \{i_1, \ldots, 
  i_l\}\subset U\) of her friends.
She does the same as she did in the pull model, except for the final step.
Instead of signing with her signing key \(\SignKey{A}\), she generates 
a \ac{MAC} \(\mu_{c_{\Key{m}}, i_j}\) for each inbox \(i_j\in S\) using the 
respective \ac{MAC} key \(\MACKey{i_j}\): \(\mu_{c_{\Key{i_j}}} 
  = \MAC_{\MACKey{i_j}}( c_{\Key{i_j}} )\).
Finally, for each \(i_j\in S\)  Alice appends \((c_{\Key{i_j}}, 
  \mu_{c_{\Key{i_j}}})\) to the inbox \(i_j\).

\subsection{Security in the Push Model}\label{sec:PushModelSec}
% XXX Review the security analysis for the push model scheme

We make the same arguments as in the pull model that the push model also 
achieves hidden-credentials and hidden-decisions.
The argument for the hidden-policy property is also similar, but here the users 
cannot even see more than their own inboxes.
However, if Bob uses the same inbox for both Alice and Eve, then Eve can infer, 
with negligible probability of error, from the verification key 
\(\VerifKey{m}\) that the same message resides in both their inboxes.
Hence, Eve can learn part of the access policy.
If Eve can make an exhaustive search of all objects in the system, then she can 
learn the policy even if every user uses unique inboxes for each friend.

The push model in general is more privacy-preserving than the pull model.
There are several advantages regarding the push model.
First, if a user has a different inbox for every friend, then no friend can 
infer activity by monitoring a users inbox.
This also means that if we stop receiving messages from a friend, then we 
cannot distinguish between that friend stopping posting entirely or just 
stopping posting to us.

Second, in the push model, we no longer reveal the cardinality of the recipient 
set.
As stated above, we do not know the names of the other inboxes, nothing reveals 
even if there is more than our inbox who received the message.
Even if Eve would control the majority of the storage nodes, she cannot 
distinguish the origin of two requests and, thus, she cannot relate all 
requests to a single event.

\subsection{Group Management}\label{sec:GroupManagement}
% XXX Review the section on group management

Our scheme is, as is general \ac{BE}, designed to broadcast a message to 
a dynamically changing group.
This means that we can easily change the recipient group.
However, when a new user, say Bob, is added to the group, we might want to give 
Bob access to old messages.
In our scheme we have to encrypt the message key \(k_m\) for every message 
\(m\) that we want Bob to access.

Similarly as for adding a user, when we remove a user, say Eve, from a group, 
we might want to remove Eve's clearances for the objects.
First, we can argue whether we should remove these or not.
Since Eve has had access to an object, she might already keep a copy anyway.
If we remove her clearance, then she learns that we have removed her from the 
group.
However, if we want to remove Eve's clearance, then we will have to re-encrypt 
all objects she had access to.
This is easier in the pull model, because in the push model we also need to 
update the entries in all other users' inboxes.


%\section{Extensions}\label{sec:Extensions}
%% XXX Write about possible extensions to improve the scheme
%For performance reasons, we also look into a trade-off between using a robust, 
%key-private IND-CCA2 \ac{PKE} scheme and a semantically secure symmetric 
%encryption scheme in the \ac{ANOBE} construction.
%The reason for this is that the symmetric operations are faster than the 
%asymmetric ones.
%This is an important factor for \acp{DOSN} during e.g.~news-feed aggregation 
%when a user comes online.
%In these situations we have to handle large amounts of data, which can lead to 
%performance problems.


\section{Performance Evaluation}\label{sec:PerformanceEvaluation}
% XXX Review the performance evaluation
% - Estimate theoretically
% - Actually do some measurements

The performance is interesting to be evaluated from two perspectives: the 
publisher's (Alice in all examples) and the subscriber's (Bob in all examples).
From the publisher's perspective, it is interesting to investigate the 
complexity of key-storage size, communication complexity for publication and 
time complexity for encryption of new material.
From the subscriber's perspective, the complexity of key-storage size and the 
time-complexity of aggregating the newest published messages are the most 
interesting aspects.

Due to their differences, our two approaches described above have some different 
complexity properties.
But they also have some similarities, and we will start with those.
The space complexity for the key management is the same for both the pull and 
push model.
If we have \(n\) friends, then we need to exchange and store \(O(n)\) keys:
we need one public key per friend.

The space complexity for the ciphertexts are \(O(n)\) for both models.
The time complexity for encryption is also \(O(n)\) for both models.
However, in the push model we need to do more operations, but this only adds up 
to maximally \(O(3n)\).
The reason is that we have to compute the signatures for the ciphertexts 
separately, and we also have to compute the \acp{MAC} for all ciphertexts.
The time complexity for decryption on the other hand is constant time, 
\(O(1)\), for the push model.
For the pull model, we need \(O(n)\) trial-and-error decryption operations.
If we add the \ac{ANOBE} tag-hint system, then we can achieve constant-time 
decryption even here.
However, this increases the needed space for the ciphertexts in the pull model.

Finally, the communication complexity for the different models differ slightly.
Asymptotically they are the same, \(O(n)\).
But we get a slight overhead in the push model.
We need to make \(n\) connections instead of one: depending on the underlying 
system, e.g.\ running Tor on a mobile device, this can be expensive.
Further, we have to transfer the verification key and signature to every inbox 
instead of just putting a copy in our index.


\section{Conclusions}\label{sec:Conclusions}
% XXX Write the conclusions
% - Ensure that the solution covers the needed properties.
\dots

%\subsection{Future Work}
%% XXX Write the future work section
%% - Accountability: Alice can see if someone has read her data.


\mode<presentation>{%
\section{Questions}
\begin{frame}
  \begin{center}
    Questions?
  \end{center}
\end{frame}
}


\mode<article>{%
\subsubsection{Acknowledgement}

This work is based on the initial ideas of Oleksandr Bodriagov and Gunnar 
Kreitz.
It is funded by the Swedish Foundation for Strategic Research grant SSF 
FFL09-0086 and the Swedish Research Council grand VR 2009-3793.
Finally, we would like to thank the anonymous reviewers for valuable feedback.
}

\begin{frame}
\printbibliography{}
\end{frame}
